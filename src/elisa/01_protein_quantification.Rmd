---
title: "01_protein_quantification"
author: "Tabea Soelter"
date: "2024-03-27"
output: html_document
---
**Analyzing ELISA measurements and quantifying protein abundance**

__Goal__: Determine whether protein abundance of Ab40, Ab42, and total tau is different between AD and WT mice as well as across time points using ELISA OD measurements. 

__Reproducibility__:
* GitHub: lasseignelab/230418_TS_AgingCCC
* Docker: tsoelter/rstudio_aging_ccc
    * Version: 1.0.3
* HPC: Yes
    * Resources: long partition (150hrs), 1 GPU, 6 CPUs, 65GB per CPU

__Data__:
*ELISA OD measurement CSVs*
* Names:
  1. 240319_ELISA_total_tau.csv
  2. 240319_ELISA_Ab40.csv
  3. 240319_ELISA_Ab42.csv
* Location: data/elisa/

__Analysis Plan__:
* Load necessary packages 
* Load data
  * ELISA OD measurement CSVs
* For each ELISA, determine the unknown concentrations using a 4PL curve
  * Perform stats (Testing for normality)
  * Plot panels
* Compile supp figure 1
  * Save

# Load packages
```{r}
# Time tracking
ptm <- proc.time()

# Setting seed
set.seed(42)

# Load packages
suppressPackageStartupMessages({
  library(ggplot2)
  library(rstatix)
  library(tidyverse)
  library(ggpubr)
  library(cowplot)
  library(patchwork)
  library(lintr)
  library(styler)
  library(here)
})

# Import functions
source(here("src", "functions_CCCin3xTgAD.R"))
```

# Load data
```{r}
ab40_data <- read_csv(here("data", "elisa", "240319_ELISA_Ab40.csv"))

ab42_data <- read_csv(here("data", "elisa", "240319_ELISA_Ab42.csv"))

tau_data <- read_csv(here("data", "elisa", "240319_ELISA_total_tau.csv"))
```

# Amyloid beta 40
* Human Ab 40 plate-based ELISA
* Samples were diluted with 1X PBS + protease inhibitor 1:1
  * Therefore, the dilution factor for this ELISA is 2 

## Subset data
* standard_df:
  * OD values and known concentrations of our standards
* sample_df: 
  * OD values of our 12 samples without concentrations (these we want to calculate)
* blank_df:
  * OD values of our blanks. 
  * The average of all blanks will be subtracted from all standard and sample OD values.
  * This accounts for background noise in detection.
```{r}
ab40_standard_df <- dplyr::filter(ab40_data, grepl("Std", Sample))

ab40_sample_df <- dplyr::filter(ab40_data, grepl("TS", Sample))

ab40_blank_df <- dplyr::filter(ab40_data, grepl("blank", Sample))
```

## Calculate average blank value
```{r}
ab40_blanks <- as.vector(as.matrix(ab40_blank_df[, c(2:4)]))

ab40_blank_mean <- mean(as.numeric(ab40_blanks))
```

## Calculate averages across triplicates for standards
* I am also removing background noise by subtracting by blank average.
```{r}
ab40_standard_df$OD_avg <- rowMeans(ab40_standard_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
ab40_standard_df_filt <- ab40_standard_df %>%
  column_to_rownames("Sample") %>%
  select(OD_avg, Conc)

# subtract blank value from each average OD value
ab40_standard_df_filt$OD_avg <- ab40_standard_df_filt$OD_avg - ab40_blank_mean
```

## Generate standard curve
* According to the ELISA kits protocol, a 4 parameter algorithm provides the best fit. 
  * Since recommended, we attempted this first.
```{r}
# Plot OD measurements and known concentrations
ab40_point <- ggplot(data = ab40_standard_df_filt) +
  geom_point(aes(Conc, OD_avg))

ab40_point

# Using the above plot, we estimate Mid and Bmax and run our 4 parameter model
ab40_fit <- nls(OD_avg ~ model4pl(Conc, Background, Mid, Slope, Bmax),
  data = ab40_standard_df_filt,
  start = c(Background = 0, Mid = 250, Slope = 1, Bmax = 4),
  control = nls.control(maxiter = 1000, warnOnly = TRUE)
)

# Determine how well our model correlates with our standards OD values
cor(ab40_standard_df_filt$OD_avg, predict(ab40_fit)) # 0.9999675

# Plot curve using model data
ab40_curve <- ggplot(data = ab40_standard_df_filt) +
  geom_point(aes(Conc, OD_avg)) +
  stat_function(
    data = ab40_standard_df_filt, fun = model4pl,
    args = list(
      Mid = coef(ab40_fit)["Mid"],
      Background = coef(ab40_fit)["Background"],
      Slope = coef(ab40_fit)["Slope"],
      Bmax = coef(ab40_fit)["Bmax"]
    )
  )

ab40_curve
```

## Save intermediate plots
```{r}
png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "ab40_point_plot.png"
))
ab40_point
dev.off()

png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "ab40_fitted_curve.png"
))
ab40_curve
dev.off()
```

## Calculate averages for samples across triplicates
```{r}
ab40_sample_df$OD_avg <- rowMeans(ab40_sample_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
ab40_sample_df_filt <- ab40_sample_df %>%
  column_to_rownames("Sample") %>%
  dplyr::select(OD_avg)

# subtract blank value from each average OD value
ab40_sample_df_filt$OD_avg <- ab40_sample_df_filt$OD_avg - ab40_blank_mean
```

## Calculate concentrations for samples from OD values
* Using the model we just built, we calculate the concentrations of our samples.
```{r}
ab40_sample_df_filt$Conc <-
  calculate_concentration(coef(ab40_fit)["Background"], # 0.09488513
                          coef(ab40_fit)["Mid"], # 307.798
                          coef(ab40_fit)["Slope"], # 1.948053
                          coef(ab40_fit)["Bmax"], # 4.61912
                          y = ab40_sample_df_filt$OD_avg
  )
```

## Multiply concentration values by dilution factor
* Dilution factor for our 1:1 input = 2
```{r}
ab40_sample_df_filt$Conc <- ab40_sample_df_filt$Conc * 2
```

## Add condition information
```{r}
ab40_sample_df_filt$group <- rep(c("6mWT", "6mAD", "12mWT", "12mAD"), each = 3)
```

## Testing for normality and homoscedasticity
* I will use a one-way independent ANOVA (parametric) or Kruskal wallis (non-parametric) test. 
  * Testing for normality and homoscedasticity. If our data meets these criteria, we will do an ANOVA.
  * Shapiro-wilk test of normality:
    * A non-significant p-value indicates data meets normality requirement 
  * Levene's test:
    * A non-significant p-value indicates data homoscedasticity requirement
```{r}
## Shapiro-wilk test
ab40_model <- lm(Conc ~ group, data = ab40_sample_df_filt)
shapiro_test(residuals(ab40_model)) # The p-value = 0.261

## Levene's test
ab40_sample_df_filt %>% levene_test(Conc ~ group) # The p-value = 0.524
```

## Testing for statistical significance
* Since our data is normally distributed and meets homoscedasticity requirements, I am running a one-way ANOVA.
```{r}
# ANOVA
ab40_res_aov <- ab40_sample_df_filt %>% anova_test(Conc ~ group)
ab40_res_aov # significant difference between groups, but which groups?

# Pairwise comparisons (ANOVAs + Tukey's test [multiple hypothesis correction])
ab40_pwc <- ab40_sample_df_filt %>% tukey_hsd(Conc ~ group)
ab40_pwc
```

## Plot panel A
```{r}
# filter stats for groups of interest
ab40_pwc_filt <- ab40_pwc %>%
  filter(!p.adj.signif == "ns")

filtered_df_12m <- ab40_pwc_filt[ab40_pwc_filt$group1 == "12mAD" &
  ab40_pwc_filt$group2 == "12mWT", ]

filtered_df_6m <- ab40_pwc_filt[ab40_pwc_filt$group1 == "6mAD" &
  ab40_pwc_filt$group2 == "6mWT", ]

ab40_pwc_filt_final <- rbind(filtered_df_12m, filtered_df_6m)

# plot panel A
ab40_boxplot <- ggboxplot(ab40_sample_df_filt,
  x = "group",
  y = "Conc",
  add = "jitter",
  fill = "group",
  palette = c(
    "#1F78B4",
    "#A6CEE3",
    "#1F78B4",
    "#A6CEE3"
  ),
  legend = "none"
) +
  stat_pvalue_manual(ab40_pwc_filt_final,
    label = "p.adj.signif",
    y.position = 200
  ) +
  ylim(0, 200) +
  ylab("Ab40 Concentration in ug/mL") +
  xlab("Group") +
  theme_bw() +
  theme(text = element_text(face = "bold")) +
  guides(fill = "none")

ab40_boxplot

# save plot
png(here("results", "final_outputs", "07_protein_quant", "ab40_boxplot.png"),
  width = 150,
  height = 150,
  units = "mm",
  res = 300
)
ab40_boxplot
dev.off()
```

# Amyloid beta 42
* Human Ab 42 plate-based ELISA
* Samples were diluted with 1X PBS + protease inhibitor 1:1
  * Therefore, the dilution factor for this ELISA is 2 

## Subset data
```{r}
ab42_standard_df <- dplyr::filter(ab42_data, grepl("Std", Sample))

ab42_sample_df <- dplyr::filter(ab42_data, grepl("TS", Sample))

ab42_blank_df <- dplyr::filter(ab42_data, grepl("blank", Sample))
```

## Calculate average blank value
```{r}
ab42_blanks <- as.vector(as.matrix(ab42_blank_df[, c(2:4)]))

ab42_blank_mean <- mean(as.numeric(ab42_blanks))
```

## Calculate averages across triplicates for standards
* I am also removing background noise by subtracting by blank average.
```{r}
# Remove first row, since all of our replicates of the top standard overflowed
ab42_standard_df <- ab42_standard_df[-1, ]

# Ensure OD columns are numeric
ab42_standard_df <- ab42_standard_df %>%
  mutate_at(c("OD_1", "OD_2", "OD_3"), as.numeric)

# Calculate averages
ab42_standard_df$OD_avg <- rowMeans(ab42_standard_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
ab42_standard_df_filt <- ab42_standard_df %>%
  column_to_rownames("Sample") %>%
  select(OD_avg, Conc)

# subtract blank value from each average OD value
ab42_standard_df_filt$OD_avg <- ab42_standard_df_filt$OD_avg - ab42_blank_mean
```

## Generate standard curve
* According to the ELISA kits protocol, a 4 parameter algorithm provides the best fit. 
```{r}
# Plot OD measurements and known concentrations
ab42_point <- ggplot(data = ab42_standard_df_filt) +
  geom_point(aes(Conc, OD_avg)) +
  xlim(-5, 600)

ab42_point

# Using the above plot, we estimate Mid, and Bmax for the 4 parameter model
ab42_fit <- nls(OD_avg ~ model4pl(Conc, Background, Mid, Slope, Bmax),
  data = ab42_standard_df_filt,
  start = c(Background = 0, Mid = 250, Slope = 1, Bmax = 2.5),
  control = nls.control(maxiter = 1000, warnOnly = TRUE)
)

# Determine how well our model correlates with our standards OD values
cor(ab42_standard_df_filt$OD_avg, predict(ab42_fit)) # 0.9999999

# Plot curve using model data
ab42_curve <- ggplot(data = ab42_standard_df_filt) +
  geom_point(aes(Conc, OD_avg)) +
  stat_function(
    data = ab42_standard_df_filt, fun = model4pl,
    args = list(
      Mid = coef(ab42_fit)["Mid"],
      Background = coef(ab42_fit)["Background"],
      Slope = coef(ab42_fit)["Slope"],
      Bmax = coef(ab42_fit)["Bmax"]
    )
  )

ab42_curve
```

## Save intermediate plots
```{r}
png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "ab42_point_plot.png"
))
ab42_point
dev.off()

png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "ab42_fitted_curve.png"
))
ab42_curve
dev.off()
```

## Calculate averages for samples across triplicates
```{r}
# Ensure OD columns are numeric
ab42_sample_df <- ab42_sample_df %>%
  mutate_at(c("OD_1", "OD_2", "OD_3"), as.numeric)

# Calculate averages
ab42_sample_df$OD_avg <- rowMeans(ab42_sample_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
ab42_sample_df_filt <- ab42_sample_df %>%
  column_to_rownames("Sample") %>%
  dplyr::select(OD_avg)

# subtract blank value from each average OD value
ab42_sample_df_filt$OD_avg <- ab42_sample_df_filt$OD_avg - ab42_blank_mean
```

## Calculate concentrations for samples from OD values
* Using the model we just built, we calculate the concentrations of our samples.
```{r}
ab42_sample_df_filt$Conc <-
  calculate_concentration(coef(ab42_fit)["Background"], # 0.05489
                          coef(ab42_fit)["Mid"], # 1513
                          coef(ab42_fit)["Slope"], # 1.335
                          coef(ab42_fit)["Bmax"], # 13.16
                          y = ab42_sample_df_filt$OD_avg
  )
```

## Multiply concentration values by dilution factor
* Dilution factor for our 1:1 input = 2
```{r}
ab42_sample_df_filt$Conc <- ab42_sample_df_filt$Conc * 2
```

# Replace any NaNs/NAs
* Since our WT samples had such small OD measurements for Ab42, the concentration cannot be calculated. Therefore, they are replaced by 0, as their concentration is essentially 0.
```{r}
ab42_sample_df_filt$Conc[is.nan(ab42_sample_df_filt$Conc)] <- 0
```

## Add condition information
```{r}
ab42_sample_df_filt$group <- rep(c("6mWT", "6mAD", "12mWT", "12mAD"), each = 3)
```

## Testing for normality and homoscedasticity
```{r}
## Shapiro-wilk test
ab42_model <- lm(Conc ~ group, data = ab42_sample_df_filt)
shapiro_test(residuals(ab42_model)) # The p-value = 0.3354804

## Levene's test
ab42_sample_df_filt %>% levene_test(Conc ~ group) # The p-value = 0.3933496
```

## Testing for statistical significance
* Since our data is normally distributed and meets homoscedasticity requirements, I am running a one-way ANOVA again.
```{r}
# ANOVA
ab42_res_aov <- ab42_sample_df_filt %>% anova_test(Conc ~ group)
ab42_res_aov # significant difference between groups (p-value = 0.000429)

# Pairwise comparisons (ANOVAs + Tukey's test [multiple hypothesis correction])
ab42_pwc <- ab42_sample_df_filt %>% tukey_hsd(Conc ~ group)
ab42_pwc
```

## Plot panel B
```{r}
# filter stats for groups of interest
ab42_pwc_filt <- ab42_pwc %>%
  filter(!p.adj.signif == "ns")

filtered_df_12m <- ab42_pwc_filt[ab42_pwc_filt$group1 == "12mAD" &
  ab42_pwc_filt$group2 == "12mWT", ]

filtered_df_6m <- ab42_pwc_filt[ab42_pwc_filt$group1 == "6mAD" &
  ab42_pwc_filt$group2 == "6mWT", ]

ab42_pwc_filt_final <- rbind(filtered_df_12m, filtered_df_6m)

# plot panel B
ab42_boxplot <- ggboxplot(ab42_sample_df_filt,
  x = "group",
  y = "Conc",
  add = "jitter",
  fill = "group",
  palette = c(
    "#1F78B4",
    "#A6CEE3",
    "#1F78B4",
    "#A6CEE3"
  ),
  legend = "none"
) +
  stat_pvalue_manual(ab42_pwc_filt_final,
    label = "p.adj.signif",
    y.position = 200
  ) +
  ylim(-5, 200) +
  ylab("Ab42 Concentration in ug/mL") +
  xlab("Group") +
  theme_bw() +
  theme(text = element_text(face = "bold")) +
  guides(fill = "none")

ab42_boxplot

# save plot
png(here("results", "final_outputs", "07_protein_quant", "ab42_boxplot.png"),
  width = 150,
  height = 150,
  units = "mm",
  res = 300
)
ab42_boxplot
dev.off()
```

# Total Tau
* Human Total Tau plate-based ELISA
* Samples were diluted with 1X PBS + protease inhibitor 1:1 and from that further diluted 1:100.
  * Therefore, the dilution factor for this ELISA is 300
    * The dilution factor of the initial dilution*dilution factor of the 1:100 dilution
    * 2*150 = 300

## Subset data
```{r}
tau_standard_df <- dplyr::filter(tau_data, grepl("Std", Sample))

tau_sample_df <- dplyr::filter(tau_data, grepl("TS", Sample))

tau_blank_df <- dplyr::filter(tau_data, grepl("blank", Sample))
```

## Calculate average blank value
```{r}
tau_blanks <- as.vector(as.matrix(tau_blank_df[, c(2:4)]))

tau_blank_mean <- mean(as.numeric(tau_blanks))
```

## Calculate averages across triplicates for standards
* I am also removing background noise by subtracting by blank average.
```{r}
tau_standard_df$OD_avg <- rowMeans(tau_standard_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
tau_standard_df_filt <- tau_standard_df %>%
  column_to_rownames("Sample") %>%
  select(OD_avg, Conc)

# subtract blank value from each average OD value
tau_standard_df_filt$OD_avg <- tau_standard_df_filt$OD_avg - tau_blank_mean
```

## Generate standard curve
* According to the ELISA kits protocol, a 4 parameter algorithm provides the best fit.
```{r}
# Plot OD measurements and known concentrations
tau_point <- ggplot(data = tau_standard_df_filt) +
  geom_point(aes(Conc, OD_avg))

tau_point

# Using the above plot, we estimate Mid and Bmax and run our 4 parameter model
tau_fit <- nls(OD_avg ~ model4pl(Conc, Background, Mid, Slope, Bmax),
  data = tau_standard_df_filt,
  start = c(Background = 0, Mid = 1000, Slope = 1, Bmax = 3),
  control = nls.control(maxiter = 1000, warnOnly = TRUE)
)

# Determine how well our model correlates with our standards OD values
cor(tau_standard_df_filt$OD_avg, predict(tau_fit)) # 0.9999545

# Plot curve using model data
tau_curve <- ggplot(data = tau_standard_df_filt) +
  geom_point(aes(Conc, OD_avg)) +
  stat_function(
    data = tau_standard_df_filt, fun = model4pl,
    args = list(
      Mid = coef(tau_fit)["Mid"],
      Background = coef(tau_fit)["Background"],
      Slope = coef(tau_fit)["Slope"],
      Bmax = coef(tau_fit)["Bmax"]
    )
  )

tau_curve
```

## Save intermediate plots
```{r}
png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "tau_point_plot.png"
))
tau_point
dev.off()

png(here(
  "results",
  "intermediate_outputs",
  "08_protein_quant",
  "tau_fitted_curve.png"
))
tau_curve
dev.off()
```

## Calculate averages for samples across triplicates
```{r}
tau_sample_df$OD_avg <- rowMeans(tau_sample_df[, c(2:4)], na.rm = TRUE)

# drop columns we no longer need
tau_sample_df_filt <- tau_sample_df %>%
  column_to_rownames("Sample") %>%
  dplyr::select(OD_avg)

# subtract blank value from each average OD value
tau_sample_df_filt$OD_avg <- tau_sample_df_filt$OD_avg - tau_blank_mean
```

## Calculate concentrations for samples from OD values
* Using the model we built, we calculate the concentrations of our samples.
```{r}
tau_sample_df_filt$Conc <-
  calculate_concentration(coef(tau_fit)["Background"], # 0.03666
                          coef(tau_fit)["Mid"], # 2889
                          coef(tau_fit)["Slope"], # 1.027
                          coef(tau_fit)["Bmax"], # 6.972
                          y = tau_sample_df_filt$OD_avg
  )
```

## Multiply concentration values by dilution factor
* Dilution factor = 300
```{r}
tau_sample_df_filt$Conc <- tau_sample_df_filt$Conc * 300
```

## Add condition information
```{r}
tau_sample_df_filt$group <- rep(c("6mWT", "6mAD", "12mWT", "12mAD"), each = 3)
```

## Testing for normality and homoscedasticity
```{r}
## Shapiro-wilk test
tau_model <- lm(Conc ~ group, data = tau_sample_df_filt)
shapiro_test(residuals(tau_model)) # The p-value = 0.103159

## Levene's test
tau_sample_df_filt %>% levene_test(Conc ~ group) # The p-value = 0.1982115
```

## Testing for statistical significance
* Since our data is normally distributed and meets homoscedasticity requirements, I am running a one-way ANOVA.
```{r}
# ANOVA
tau_res_aov <- tau_sample_df_filt %>% anova_test(Conc ~ group)
tau_res_aov # significant difference between groups (p = 0.000131)

# Pairwise comparisons (ANOVAs + Tukey's test multiple hypothesis correction)
tau_pwc <- tau_sample_df_filt %>% tukey_hsd(Conc ~ group)
tau_pwc
```

## Plot panel C
```{r}
# filter stats for groups of interest
tau_pwc_filt <- tau_pwc %>%
  filter(!p.adj.signif == "ns")

filtered_df_12m <- tau_pwc_filt[tau_pwc_filt$group1 == "12mAD" &
  tau_pwc_filt$group2 == "12mWT", ]

filtered_df_6m <- tau_pwc_filt[tau_pwc_filt$group1 == "6mAD" &
  tau_pwc_filt$group2 == "6mWT", ]

tau_pwc_filt_final <- rbind(filtered_df_12m, filtered_df_6m)

# Transform Conc values for plotting purposes (AD vs WT values are very diff)
tau_sample_df_filt$log10 <- log10(tau_sample_df_filt$Conc)

# plot panel C
tau_boxplot <- ggboxplot(tau_sample_df_filt,
  x = "group",
  y = "log10",
  add = "jitter",
  fill = "group",
  palette = c(
    "#1F78B4",
    "#A6CEE3",
    "#1F78B4",
    "#A6CEE3"
  ),
  legend = "none"
) +
  stat_pvalue_manual(tau_pwc_filt_final,
    label = "p.adj.signif",
    y.position = 6
  ) +
  ylim(0, 6) +
  theme_bw() +
  theme(text = element_text(face = "bold")) +
  ylab("Log10 of Total Tau Concentration in ug/mL") +
  xlab("Group") +
  guides(fill = "none")

# save plot
png(here("results", "final_outputs", "07_protein_quant", "tau_boxplot.png"),
  width = 150,
  height = 150,
  units = "mm",
  res = 300
)
tau_boxplot
dev.off()
```

# Compile final figure
```{r}
figure <- plot_grid(ab40_boxplot,
  ab42_boxplot,
  tau_boxplot,
  ncol = 3,
  labels = c("A", "B", "C")
)

figure
```

# Save final figure
```{r}
png(here("results", "final_outputs", "01_figures", "supp_figure1.png"),
  width = 300,
  height = 125,
  units = "mm",
  res = 300
)
figure
dev.off()
```

# Session Info
```{r}
sessionInfo() # see below
```
R version 4.2.3 (2023-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 22.04.4 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] here_1.0.1      styler_1.9.1    lintr_3.0.2     patchwork_1.1.2 cowplot_1.1.1  
 [6] ggpubr_0.6.0    lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.1    
[11] purrr_1.0.1     readr_2.1.4     tidyr_1.3.0     tibble_3.2.1    tidyverse_2.0.0
[16] rstatix_0.7.2   ggplot2_3.4.2  

loaded via a namespace (and not attached):
 [1] ps_1.7.5          rprojroot_2.0.3   digest_0.6.31     utf8_1.2.3       
 [5] R6_2.5.1          backports_1.4.1   pillar_1.9.0      rlang_1.1.0      
 [9] lazyeval_0.2.2    rstudioapi_0.14   car_3.1-2         callr_3.7.3      
[13] R.utils_2.12.2    R.oo_1.25.0       desc_1.4.2        labeling_0.4.2   
[17] bit_4.0.5         munsell_0.5.0     broom_1.0.4       compiler_4.2.3   
[21] xfun_0.38         pkgconfig_2.0.3   tidyselect_1.2.0  fansi_1.0.4      
[25] crayon_1.5.2      tzdb_0.3.0        withr_2.5.0       R.methodsS3_1.8.2
[29] grid_4.2.3        gtable_0.3.3      lifecycle_1.0.3   magrittr_2.0.3   
[33] scales_1.2.1      cli_3.6.1         stringi_1.7.12    vroom_1.6.1      
[37] carData_3.0-5     farver_2.1.1      ggsignif_0.6.4    remotes_2.4.2    
[41] rex_1.2.1         xml2_1.3.3        generics_0.1.3    vctrs_0.6.2      
[45] cyclocomp_1.1.0   tools_4.2.3       bit64_4.0.5       R.cache_0.16.0   
[49] glue_1.6.2        hms_1.1.3         processx_3.8.1    abind_1.4-5      
[53] parallel_4.2.3    timechange_0.2.0  colorspace_2.1-0  knitr_1.42

# Time tracking
```{r}
fptm <- proc.time() - ptm

# convert to minutes
(fptm[3] / 60)

# Time elapsed: < 5 minutes
```

# Reproducibility
```{r eval=FALSE, include=FALSE}
# styler
style_file(here(
  "src",
  "elisa",
  "01_protein_quantification.Rmd"
))

# lintr
lint(filename = here(
  "src",
  "elisa",
  "01_protein_quantification.Rmd"
))
```
